# -*- coding: utf-8 -*-
"""Movie_recommender.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qp5Ms5TFGI-sRS3TwQCfXh2o-0RyYAuc
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib as ml
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
ml.style.use('ggplot')

# Reading csv files in Google Colab.
# Step1 : Mount your Google Drive to colab
# Step2 : Provide the path to read_csv

from google.colab import drive 
drive.mount('/content/gdrive')

movie = pd.read_csv('/content/gdrive/My Drive/movie.csv')
movie.head(20)

movie.drop('genres', axis = 1)

movie.isnull().sum()

movie.info()

rating = pd.read_csv('/content/gdrive/My Drive/rating.csv')
rating.head()

rating.isnull().sum()

rating.drop('timestamp', axis = 1, inplace = True)

"""**ATTEMPT TO SEPARATE OUT THE GENRES**"""

movie.genres.str.split('|').tolist()

new = pd.DataFrame(movie.genres.str.split('|').tolist())
new.drop([5,6,7,8,9],axis=1)

# Creating new columns with each column containing the separated out genres in each string

movie['new_genre1'] = new[0]
movie['new_genre2'] = new[1]
movie['new_genre3'] = new[2]
movie['new_genre4'] = new[3]
movie['new_genre5'] = new[4]

movie.head(20)

"""**PLOTTING FREQUENCIES OF RATINGS**"""

# Plot frequencies of ratings
plt.hist(rating['rating'], bins=20,color="teal",edgecolor="black")
plt.xlabel("Ratings")
plt.title("No. of ratings of each rate type")
plt.show()

"""**PLOTTING RATINGS PER MOVIE**"""

sample = rating[['movieId','rating']].groupby('movieId').count()
sample

sample.rating.values

plt.scatter(sample.index,sample.rating.values,edgecolor='black')
plt.xlabel("Movie Id")
plt.ylabel("Ratings per movie")
plt.title("Ratings v/s movies")
plt.show()

"""**PLOTTING RATINGS PER USER**"""

sample1 = rating[['rating','userId']].groupby('userId').count()
sample1

# Plot ratings per movie

# Scatter plot
plt.scatter(sample1.index,sample1.rating.values,edgecolors='black')
plt.xlabel("User Id")
plt.ylabel("Ratings per user")
plt.title("Ratings v/s users")
plt.show()

"""**CREATING A NEW DATASET THAT CONTAINS THE POPULAR MOVIES. POPULARITY MEASURED ON VOTES EARNED.**"""

# Get those users who are active.
# Measurement of activeness ? Have voted > 200 times

user = rating['userId'].value_counts() > 200
active = user[user].index.tolist()
active

# Extract only these indices

new_rating = rating[rating['userId'].isin(active)]
new_rating.head(20)

# Merge the two datasets based on common/primary key, i.e, movieId

df = movie.merge(new_rating, on = 'movieId')
df

# Get the most popular movies, i.e, the movies which have been voted > 60 times

m = df['movieId'].value_counts() > 60
popular = m[m].index.tolist()
popular

# Extract only these indices

final = df[df['movieId'].isin(popular)]
final

# Now, one user may have voted more than once for the same movie with the same vote. Remove those duplicates.

final.drop_duplicates(subset=['userId','title'])
# Notice the change in shape.

# Get the ratings per movie per user.
# How ? Create a pivot table

pvt = final.pivot_table(index='title',columns='userId',values='rating')
pvt

# A model can't work on non-numerical data. So convert all NaN to -1.
pvt.fillna(-1,inplace=True)
pvt

"""**WORKING ON BUILDING THE MODEL'S REQUIREMENTS**"""

# But the model cannot work on a pivot table. So it is flattened out to a sparse matrix.

from scipy.sparse import csr_matrix
spm = csr_matrix(pvt)
spm

# Creating, training and testing the model

from sklearn.neighbors import NearestNeighbors
nn = NearestNeighbors(algorithm = 'brute')
nn.fit(spm)

# Get the testing data
# Getting recommendations for one of the best movies : (500) Days Of Summer (2009)
# It is at index 4

pvt.index[4]

# The test data will be the entire row of index 4, reshaped to a 1 x 26599 array.
test = pvt.iloc[4,:].values.reshape(1,26599)

distance, suggested = nn.kneighbors(test,n_neighbors=5)

# distance returns a list of distances of each predicted point from test point
distance

# suggested will give us the indices of the recommended movies.
suggested

# Let's check
# (500) Days of Summer (2009) is a romantic movie.

pvt.index[1969]

# Crazy, Stupid, Love. (2011) is another excellent romantic/fantasy movie

pvt.index[114]

pvt.index[194]

# Adventureland (2009) is a fiction/romance/fantasy movie

# Hence our model works

# Testing another test row.
# Test movie : 2012 (2009)

pvt.index[60]

test1 = pvt.iloc[60,:].values.reshape(1,26599)
dist, rec = nn.kneighbors(test1, n_neighbors=7)

dist

rec

# Let's check

pvt.index[4936]

# Both 2012 and Legion are doomsday based fantasy movies.